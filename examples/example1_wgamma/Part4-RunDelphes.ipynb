{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A MadMiner Example Analysis -  Analyzing dim6 operators in $W\\gamma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first load all the python libraries again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "madminer_src_path = \"/Users/felixkling/Documents/GitHub/madminer\"\n",
    "sys.path.append(madminer_src_path)\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "% matplotlib inline\n",
    "\n",
    "from madminer.delphes import DelphesProcessor\n",
    "from madminer.sampling import combine_and_shuffle\n",
    "from madminer.utils.particle import MadMinerParticle\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import constant_benchmark_theta, multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enter here the path to your MG5 root directory. This notebook assumes that you installed Delphes and Pythia through MG5. \n",
    "\n",
    "**This needs to be updated by the user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_dir = '/Users/felixkling/work/MG5_aMC_v2_6_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Run detector simulation and extract observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Initialize DelphesProcessor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `madminer.delphes` wraps around Delphes, a popular fast detector simulation. In addition to simulating the detector, it allows for the fast extraction of observables, which are saved in the MadMiner HDF5 file. The central object is an instance of the `DelphesProcessor` class, which has to be initialized with a MadMiner file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:36  \n",
      "09:36  ------------------------------------------------------------\n",
      "09:36  |                                                          |\n",
      "09:36  |  MadMiner v0.1.1                                         |\n",
      "09:36  |                                                          |\n",
      "09:36  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "09:36  |                                                          |\n",
      "09:36  ------------------------------------------------------------\n",
      "09:36  \n"
     ]
    }
   ],
   "source": [
    "dp = DelphesProcessor('data/madminer_example.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Run Delphes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the DelphesProcessor object, one can add a number of HepMC event samples (the output of running MadGraph and Pythia) and have it run Delphes (the hepmc sample is mainly needed to ensure that the the benchmark points are assigned correctly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:36  Running Delphes (/Users/felixkling/work/MG5_aMC_v2_6_2/Delphes) on event sample at mg_processes/wgamma/Events/run_01/tag_1_pythia8_events.hepmc.gz\n"
     ]
    }
   ],
   "source": [
    "dp.add_hepmc_sample(\n",
    "    'mg_processes/wgamma/Events/run_01/tag_1_pythia8_events.hepmc.gz',\n",
    "    sampled_from_benchmark='sm'\n",
    ")\n",
    "\n",
    "dp.run_delphes(\n",
    "    delphes_directory=mg_dir + '/Delphes',\n",
    "    delphes_card='cards/delphes_card.dat',\n",
    "    log_file='logs/wgamma/log_delphes.log',\n",
    "    initial_command='source ~/.bashrc'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the definition of observables through a name and a python expression. For the latter, you can use the objects `j[i]`, `e[i]`, `mu[i]`, `a[i]`, `met`, where the indices `i` refer to a ordering by the transverse momentum. All of these objects inherit from scikit-hep [LorentzVectors](http://scikit-hep.org/api/math.html#vector-classes), see the link for a documentation of their properties. In addition, they have `charge` and `pdg_id` properties.\n",
    "\n",
    "There is an optional keyword `required`. If `required=True`, we will only keep events where the observable can be parsed, i.e. all involved particles have been detected. If `required=False`, un-parseable observables will be filled with the value of another keyword `default`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c) Extract Detector Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define again some functions for observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mt(leptons, photons, jets, met):\n",
    "    # Particles\n",
    "    if len(leptons) < 1:\n",
    "        raise RuntimeError()\n",
    "    l = leptons[0]\n",
    "    \n",
    "    # Transverse mass and Delta\n",
    "    cos_delta_phi = np.cos(l.phi() - met.phi())\n",
    "    mt = (2 * l.pt * met.pt * (1. - cos_delta_phi))**0.5\n",
    "    \n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phi(leptons, photons, jets, met):\n",
    "    # Parameters\n",
    "    mw = 80.4\n",
    "    \n",
    "    # Particles\n",
    "    if len(leptons) < 1 or len(photons) < 1:\n",
    "        raise RuntimeError()\n",
    "    \n",
    "    l = leptons[0]\n",
    "    a = photons[0]\n",
    "    \n",
    "    # Transverse mass and Delta\n",
    "    mt = calculate_mt(leptons, photons, jets, met)\n",
    "    deltasq = 0.\n",
    "    if met.pt > 0. and l.pt > 0.:\n",
    "        deltasq = (mw**2 - mt**2) / (2. * met.pt * l.pt)\n",
    "    \n",
    "    # v reconstruction, \"normal\" case\n",
    "    if deltasq > 0.:\n",
    "        # Two solutions\n",
    "        temp = np.log(1 + deltasq**0.5 * (2 + deltasq)**0.5 + deltasq)\n",
    "        eta_v_plus = l.eta + temp\n",
    "        eta_v_minus = l.eta - temp\n",
    "        \n",
    "        # Randomly select one of them\n",
    "        dice = np.random.rand()\n",
    "        if dice > 0.5:\n",
    "            eta_v = eta_v_plus\n",
    "        else:\n",
    "            eta_v = eta_v_minus\n",
    "            \n",
    "    # v reconstruction, \"other\" case\n",
    "    else:\n",
    "        eta_v = l.eta\n",
    "        \n",
    "    # v particle\n",
    "    v = MadMinerParticle()\n",
    "    v.setptetaphim(met.pt, eta_v, met.phi(), 0.)\n",
    "    \n",
    "    # W and Wgamma reconstruction\n",
    "    w = l + v\n",
    "    vv = w + a\n",
    "    \n",
    "    # Boost into VV frame\n",
    "    v_ = v.boost(vv.boostvector)\n",
    "    l_ = l.boost(vv.boostvector)\n",
    "    a_ = a.boost(vv.boostvector)\n",
    "    w_ = w.boost(vv.boostvector)\n",
    "    r_ = vv # vv.boost(vv.boostvector)\n",
    "\n",
    "    # Calculate axes of \"special frame\" (1708.07823)\n",
    "    z_ = w_.vector.unit()\n",
    "    x_ = (r_.vector - z_ * r_.vector.dot(z_)).unit()\n",
    "    y_ = z_.cross(x_)\n",
    "    \n",
    "    # Calculate x and y components of lepton wrt special x_, y_, z_ system\n",
    "    lx_ = l_.vector.dot(x_)\n",
    "    ly_ = l_.vector.dot(y_)\n",
    "    \n",
    "    # Calculate phi\n",
    "    phi = math.atan2(ly_, lx_)\n",
    "    \n",
    "    return phi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.add_observable('px_l', 'mu[0].px',required=True)\n",
    "dp.add_observable('px_v', 'met.px',required=True)\n",
    "dp.add_observable('px_a', 'a[0].px',required=True)\n",
    "\n",
    "dp.add_observable('py_l', 'mu[0].py',required=True)\n",
    "dp.add_observable('py_v', 'met.py',required=True)\n",
    "dp.add_observable('py_a', 'a[0].py',required=True)\n",
    "\n",
    "dp.add_observable('pz_l', 'mu[0].pz',required=True)\n",
    "dp.add_observable('pz_a', 'a[0].pz',required=True)\n",
    "\n",
    "dp.add_observable('e_l', 'mu[0].e',required=True)\n",
    "dp.add_observable('e_a', 'a[0].e',required=True)\n",
    "\n",
    "dp.add_observable('pt_l', 'mu[0].pt',required=True)\n",
    "dp.add_observable('pt_v', 'met.pt',required=True)\n",
    "dp.add_observable('pt_a', 'a[0].pt',required=True)\n",
    "\n",
    "dp.add_observable('eta_l', 'mu[0].eta',required=True)\n",
    "dp.add_observable('eta_a', 'a[0].eta',required=True)\n",
    "\n",
    "dp.add_observable('dphi_lv', 'mu[0].deltaphi(met)',required=True)\n",
    "dp.add_observable('dphi_la', 'mu[0].deltaphi(a[0])',required=True)\n",
    "dp.add_observable('dphi_va', 'met.deltaphi(a[0])',required=True)\n",
    "\n",
    "dp.add_observable('m_la', '(mu[0] + a[0]).m',required=True)\n",
    "\n",
    "dp.add_observable_from_function('mt',calculate_mt,required=True)\n",
    "dp.add_observable_from_function('phi_resurrection',calculate_phi,required=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add cuts, again in parse-able strings. In addition to the objects discussed above, they can contain the observables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp.add_cut('pt_a > 250.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `analyse_delphes_samples` then calculates all observables from the Delphes ROOT file(s) generated before and applies the cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:40  Analysing Delphes sample mg_processes/wgamma/Events/run_01/tag_1_pythia8_events_delphes.root\n",
      "09:43    77552 / 100000 events pass everything\n"
     ]
    }
   ],
   "source": [
    "dp.analyse_delphes_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the observables and the weights are then saved in the HDF5 file. It is possible to overwrite the same file, or to leave the original file intact and save all the data into a new file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.save('data/madminer_detectordata_0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One side remark: For the detector simulation and calculation of observables, different users might have very different requirements. While a phenomenologist might be content with the fast detector simulation from Delphes, an experimental analysis might require the full simulation through Geant4. We therefore intend this part to be interchangeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce disk usage, you can generate several small event samples with the steps given above, and combine them now. Note that (for now) it is essential that all of them are generated with the same setup, including the same benchmark points / morphing basis!\n",
    "\n",
    "In our case we only have one sample, so this is not strictly necessary, but we still include it for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:43  Copying setup from data/madminer_detectordata_0.h5 to data/madminer_detectordata.h5\n",
      "09:43  Loading samples from file 1 / 1 at data/madminer_detectordata_0.h5\n"
     ]
    }
   ],
   "source": [
    "combine_and_shuffle(\n",
    "    ['data/madminer_detectordata_0.h5'],\n",
    "    'data/madminer_detectordata.h5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d) Extract Pythia Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the pythia level data from the hepmc file. This can be done with the option `generator_truth=False` in `DelphesProcessor.analyse_delphes_samples()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:43  Analysing Delphes sample mg_processes/wgamma/Events/run_01/tag_1_pythia8_events_delphes.root\n",
      "09:46    77552 / 100000 events pass everything\n",
      "09:46  Copying setup from data/madminer_pythiadata_0.h5 to data/madminer_pythiadata.h5\n",
      "09:46  Loading samples from file 1 / 1 at data/madminer_pythiadata_0.h5\n"
     ]
    }
   ],
   "source": [
    "dp.analyse_delphes_samples()\n",
    "dp.save('data/madminer_pythiadata_0.h5')\n",
    "combine_and_shuffle(\n",
    "    ['data/madminer_pythiadata_0.h5'],\n",
    "    'data/madminer_pythiadata.h5'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
