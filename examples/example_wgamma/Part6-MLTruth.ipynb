{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A MadMiner Example Analysis -  Analyzing dim6 operators in $W\\gamma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first load all the python libraries again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "madminer_src_path = \"/Users/felixkling/Documents/GitHub/madminer\"\n",
    "sys.path.append(madminer_src_path)\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "% matplotlib inline\n",
    "\n",
    "from madminer.fisherinformation import FisherInformation\n",
    "from madminer.fisherinformation import project_information,profile_information\n",
    "\n",
    "from madminer.plotting import plot_fisher_information_contours_2d\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import constant_benchmark_theta, multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Obtaining the Fisher Information using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce some alternative steps which will lead us to an estimator for the score at a reference point (SALLY) and the expected Fisher information. Along the way, we'll introduce some powerful ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not forget anything later, let us globaly define the number of events in the MG sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhedatafile = 'data/madminer_lhedata.h5'\n",
    "nsamples = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a) Make (unweighted) training and test samples with augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is handled by the `madminer.sampling` class `SampleAugmenter`. From all the data we have in the MadMiner file now, it extracts unweighted samples including the augmented data, that is needed as training and evaluation data for the machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:24  \n",
      "22:24  ------------------------------------------------------------\n",
      "22:24  |                                                          |\n",
      "22:24  |  MadMiner v0.1.0                                         |\n",
      "22:24  |                                                          |\n",
      "22:24  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "22:24  |                                                          |\n",
      "22:24  ------------------------------------------------------------\n",
      "22:24  \n",
      "22:24  Loading data from data/madminer_lhedata.h5\n",
      "22:24  Found 2 parameters:\n",
      "22:24     CWL2 (LHA: dim6 2, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:24     CPWL2 (LHA: dim6 5, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:24  Found 6 benchmarks:\n",
      "22:24     sm: CWL2 = 0.00e+00, CPWL2 = 0.00e+00\n",
      "22:24     w: CWL2 = 20.00, CPWL2 = 0.00e+00\n",
      "22:24     morphing_basis_vector_2: CWL2 = -3.26e+01, CPWL2 = -4.46e+01\n",
      "22:24     morphing_basis_vector_3: CWL2 = 8.14, CPWL2 = -3.50e+01\n",
      "22:24     morphing_basis_vector_4: CWL2 = -3.51e+01, CPWL2 = 32.41\n",
      "22:24     morphing_basis_vector_5: CWL2 = 5.86, CPWL2 = 39.09\n",
      "22:24  Found 26 observables: px_l, px_v, px_a, py_l, py_v, py_a, pz_l, pz_v, pz_a, e_l, e_v, e_a, pt_l, pt_v, pt_a, eta_l, eta_v, eta_a, dphi_lv, dphi_la, dphi_va, m_lv, m_lva, m_la, mtrans, phi_resurrection\n",
      "22:24  Found 100000 events\n",
      "22:24  Found morphing setup with 6 components\n"
     ]
    }
   ],
   "source": [
    "sa = SampleAugmenter(lhedatafile, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant `SampleAugmenter` function for local score estimators is `extract_samples_train_local()`. For the argument `theta` you can use the helper functions `constant_benchmark_theta()`, `multiple_benchmark_thetas()`, `constant_morphing_theta()`, `multiple_morphing_thetas()`, and `random_morphing_thetas()`. \n",
    "\n",
    "Here we are mostly interested in evaluating the Fisher Info at the SM benchmark. We will create two sets of samples, one for training and one for testing. In particular, for training we create `n_estimator` sets of samples. This will allow us later to better investigate the uncertainty of the estimates Fisher Information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:24  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:24  Effective number of samples: 50000.00000004142\n",
      "22:24  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:24  Effective number of samples: 50000.00000004142\n",
      "22:24  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:24  Effective number of samples: 50000.00000004142\n",
      "22:24  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:24  Effective number of samples: 50000.00000004142\n",
      "22:24  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:24  Effective number of samples: 50000.00000004142\n",
      "22:24  Extracting evaluation sample. Sampling according to (u'benchmark', u'sm')\n",
      "22:24  Effective number of samples: 49999.00000004142\n"
     ]
    }
   ],
   "source": [
    "#Define n_estimator\n",
    "n_estimators = 5\n",
    "\n",
    "#augment train sample\n",
    "for i in range(n_estimators):\n",
    "    x, theta, t_xz = sa.extract_samples_train_local(\n",
    "        theta=constant_benchmark_theta('sm'),\n",
    "        n_samples=int(nsamples/2),\n",
    "        folder='./data/samples_ensemble/',\n",
    "        filename='train{}'.format(i)\n",
    "    )\n",
    "\n",
    "#augment test sample\n",
    "x, theta = sa.extract_samples_test(\n",
    "    theta=constant_benchmark_theta('sm'),\n",
    "    n_samples=int(nsamples/2),\n",
    "    folder='./data/samples_ensemble/',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b)  Train a neural network to estimate the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to build a neural network. Only this time, instead of the likelihood ratio itself, we will estimate the gradient of the log likelihood with respect to the theory parameters -- the score. To be precise, the output of the neural network is an estimate of the score at some reference parameter point, for instance the Standard Model. A neural network that estimates this \"local\" score can be used to calculate the Fisher information at that point. The estimated score can also be used as a machine learning version of Optimal Observables, and likelihoods can be estimated based on density estimation in the estimated score space. This method for likelihood ratio estimation is called SALLY, and there is a closely related version called SALLINO. Both are explained in [\"Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00013) and [\"A Guide to Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00020).\n",
    "\n",
    "Again, the central object for this is the `madminer.ml.MLForge` class to get a single estimator. Additionally, instead of using a single neural network to estimate the likelihood ratio, score, or Fisher information, we can use an ensemble of such estimators. That provides us with a more reliable mean prediction as well as a measure of the uncertainty. The class `madminer.ml.EnsembleForge` automates this process. Currently, it only supports SALLY estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleForge(estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we can train all estimators simultaneously with `train_all()` and save the ensemble to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:24  Training 5 estimators in ensemble\n",
      "22:24  Training estimator 1 / 5 in ensemble\n",
      "22:24  Starting training\n",
      "22:24    Method:                 sally\n",
      "22:24    Training data: x at data/samples_ensemble/x_train0.npy\n",
      "22:24                   t_xz (theta0) at  data/samples_ensemble/t_xz_train0.npy\n",
      "22:24    Features:               all\n",
      "22:24    Method:                 sally\n",
      "22:24    Hidden layers:          (100, 100)\n",
      "22:24    Activation function:    tanh\n",
      "22:24    Batch size:             128\n",
      "22:24    Trainer:                amsgrad\n",
      "22:24    Epochs:                 50\n",
      "22:24    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:24    Validation split:       None\n",
      "22:24    Early stopping:         True\n",
      "22:24    Scale inputs:           True\n",
      "22:24    Shuffle labels          False\n",
      "22:24    Regularization:         None\n",
      "22:24  Loading training data\n",
      "22:24  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:24  Rescaling inputs\n",
      "22:24  Creating model for method sally\n",
      "22:24  Training model\n",
      "22:24    Epoch 5: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:24    Epoch 10: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:24    Epoch 15: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:24    Epoch 20: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:24    Epoch 25: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:24    Epoch 30: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 35: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 40: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 45: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 50: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25  Finished training\n",
      "22:25  Training estimator 2 / 5 in ensemble\n",
      "22:25  Starting training\n",
      "22:25    Method:                 sally\n",
      "22:25    Training data: x at data/samples_ensemble/x_train1.npy\n",
      "22:25                   t_xz (theta0) at  data/samples_ensemble/t_xz_train1.npy\n",
      "22:25    Features:               all\n",
      "22:25    Method:                 sally\n",
      "22:25    Hidden layers:          (100, 100)\n",
      "22:25    Activation function:    tanh\n",
      "22:25    Batch size:             128\n",
      "22:25    Trainer:                amsgrad\n",
      "22:25    Epochs:                 50\n",
      "22:25    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:25    Validation split:       None\n",
      "22:25    Early stopping:         True\n",
      "22:25    Scale inputs:           True\n",
      "22:25    Shuffle labels          False\n",
      "22:25    Regularization:         None\n",
      "22:25  Loading training data\n",
      "22:25  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:25  Rescaling inputs\n",
      "22:25  Creating model for method sally\n",
      "22:25  Training model\n",
      "22:25    Epoch 5: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:25    Epoch 10: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:25    Epoch 15: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 20: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 25: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 30: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:25    Epoch 35: train loss 0.0002 (mse_score: 0.0002)\n",
      "22:26    Epoch 40: train loss 0.0002 (mse_score: 0.0002)\n",
      "22:26    Epoch 45: train loss 0.0002 (mse_score: 0.0002)\n",
      "22:26    Epoch 50: train loss 0.0002 (mse_score: 0.0002)\n",
      "22:26  Finished training\n",
      "22:26  Training estimator 3 / 5 in ensemble\n",
      "22:26  Starting training\n",
      "22:26    Method:                 sally\n",
      "22:26    Training data: x at data/samples_ensemble/x_train2.npy\n",
      "22:26                   t_xz (theta0) at  data/samples_ensemble/t_xz_train2.npy\n",
      "22:26    Features:               all\n",
      "22:26    Method:                 sally\n",
      "22:26    Hidden layers:          (100, 100)\n",
      "22:26    Activation function:    tanh\n",
      "22:26    Batch size:             128\n",
      "22:26    Trainer:                amsgrad\n",
      "22:26    Epochs:                 50\n",
      "22:26    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:26    Validation split:       None\n",
      "22:26    Early stopping:         True\n",
      "22:26    Scale inputs:           True\n",
      "22:26    Shuffle labels          False\n",
      "22:26    Regularization:         None\n",
      "22:26  Loading training data\n",
      "22:26  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:26  Rescaling inputs\n",
      "22:26  Creating model for method sally\n",
      "22:26  Training model\n",
      "22:26    Epoch 5: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:26    Epoch 10: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:26    Epoch 15: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:26    Epoch 20: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:26    Epoch 25: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:26    Epoch 30: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:26    Epoch 35: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:26    Epoch 40: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:26    Epoch 45: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:26    Epoch 50: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:26  Finished training\n",
      "22:26  Training estimator 4 / 5 in ensemble\n",
      "22:26  Starting training\n",
      "22:26    Method:                 sally\n",
      "22:26    Training data: x at data/samples_ensemble/x_train3.npy\n",
      "22:26                   t_xz (theta0) at  data/samples_ensemble/t_xz_train3.npy\n",
      "22:26    Features:               all\n",
      "22:26    Method:                 sally\n",
      "22:26    Hidden layers:          (100, 100)\n",
      "22:26    Activation function:    tanh\n",
      "22:26    Batch size:             128\n",
      "22:26    Trainer:                amsgrad\n",
      "22:26    Epochs:                 50\n",
      "22:26    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:26    Validation split:       None\n",
      "22:26    Early stopping:         True\n",
      "22:26    Scale inputs:           True\n",
      "22:26    Shuffle labels          False\n",
      "22:26    Regularization:         None\n",
      "22:26  Loading training data\n",
      "22:26  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:26  Rescaling inputs\n",
      "22:26  Creating model for method sally\n",
      "22:26  Training model\n",
      "22:27    Epoch 5: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:27    Epoch 10: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:27    Epoch 15: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:27    Epoch 20: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:27    Epoch 25: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:27    Epoch 30: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:27    Epoch 35: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:27    Epoch 40: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:27    Epoch 45: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:27    Epoch 50: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:27  Finished training\n",
      "22:27  Training estimator 5 / 5 in ensemble\n",
      "22:27  Starting training\n",
      "22:27    Method:                 sally\n",
      "22:27    Training data: x at data/samples_ensemble/x_train4.npy\n",
      "22:27                   t_xz (theta0) at  data/samples_ensemble/t_xz_train4.npy\n",
      "22:27    Features:               all\n",
      "22:27    Method:                 sally\n",
      "22:27    Hidden layers:          (100, 100)\n",
      "22:27    Activation function:    tanh\n",
      "22:27    Batch size:             128\n",
      "22:27    Trainer:                amsgrad\n",
      "22:27    Epochs:                 50\n",
      "22:27    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:27    Validation split:       None\n",
      "22:27    Early stopping:         True\n",
      "22:27    Scale inputs:           True\n",
      "22:27    Shuffle labels          False\n",
      "22:27    Regularization:         None\n",
      "22:27  Loading training data\n",
      "22:27  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:27  Rescaling inputs\n",
      "22:27  Creating model for method sally\n",
      "22:27  Training model\n",
      "22:27    Epoch 5: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:27    Epoch 10: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:27    Epoch 15: train loss 0.0004 (mse_score: 0.0004)\n",
      "22:27    Epoch 20: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28    Epoch 25: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28    Epoch 30: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28    Epoch 35: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28    Epoch 40: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28    Epoch 45: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28    Epoch 50: train loss 0.0003 (mse_score: 0.0003)\n",
      "22:28  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble.train_all(\n",
    "    method='sally',\n",
    "    x_filename=['data/samples_ensemble/x_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=['data/samples_ensemble/t_xz_train{}.npy'.format(i) for i in range(n_estimators)]\n",
    ")\n",
    "\n",
    "ensemble.save('models/samples_ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c)  Train a neural network with subset of observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train the EnsembleForge with just a subset of observables. This is done with the option `features`. In the following example we drop the unobservable degrees of freedom of the neutrino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:28  Training 5 estimators in ensemble\n",
      "22:28  Training estimator 1 / 5 in ensemble\n",
      "22:28  Starting training\n",
      "22:28    Method:                 sally\n",
      "22:28    Training data: x at data/samples_ensemble/x_train0.npy\n",
      "22:28                   t_xz (theta0) at  data/samples_ensemble/t_xz_train0.npy\n",
      "22:28    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25)\n",
      "22:28    Method:                 sally\n",
      "22:28    Hidden layers:          (100, 100)\n",
      "22:28    Activation function:    tanh\n",
      "22:28    Batch size:             128\n",
      "22:28    Trainer:                amsgrad\n",
      "22:28    Epochs:                 50\n",
      "22:28    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:28    Validation split:       None\n",
      "22:28    Early stopping:         True\n",
      "22:28    Scale inputs:           True\n",
      "22:28    Shuffle labels          False\n",
      "22:28    Regularization:         None\n",
      "22:28  Loading training data\n",
      "22:28  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:28  Rescaling inputs\n",
      "22:28  Only using 21 of 26 observables\n",
      "22:28  Creating model for method sally\n",
      "22:28  Training model\n",
      "22:28    Epoch 5: train loss 0.0008 (mse_score: 0.0008)\n",
      "22:28    Epoch 10: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:28    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:28    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:28    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:28    Epoch 30: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:28    Epoch 35: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:28    Epoch 40: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:28    Epoch 45: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29  Finished training\n",
      "22:29  Training estimator 2 / 5 in ensemble\n",
      "22:29  Starting training\n",
      "22:29    Method:                 sally\n",
      "22:29    Training data: x at data/samples_ensemble/x_train1.npy\n",
      "22:29                   t_xz (theta0) at  data/samples_ensemble/t_xz_train1.npy\n",
      "22:29    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25)\n",
      "22:29    Method:                 sally\n",
      "22:29    Hidden layers:          (100, 100)\n",
      "22:29    Activation function:    tanh\n",
      "22:29    Batch size:             128\n",
      "22:29    Trainer:                amsgrad\n",
      "22:29    Epochs:                 50\n",
      "22:29    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:29    Validation split:       None\n",
      "22:29    Early stopping:         True\n",
      "22:29    Scale inputs:           True\n",
      "22:29    Shuffle labels          False\n",
      "22:29    Regularization:         None\n",
      "22:29  Loading training data\n",
      "22:29  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:29  Rescaling inputs\n",
      "22:29  Only using 21 of 26 observables\n",
      "22:29  Creating model for method sally\n",
      "22:29  Training model\n",
      "22:29    Epoch 5: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:29    Epoch 10: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:29    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:29    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:29    Epoch 25: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29    Epoch 30: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29    Epoch 35: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29    Epoch 40: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29    Epoch 45: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:29  Finished training\n",
      "22:29  Training estimator 3 / 5 in ensemble\n",
      "22:29  Starting training\n",
      "22:29    Method:                 sally\n",
      "22:29    Training data: x at data/samples_ensemble/x_train2.npy\n",
      "22:29                   t_xz (theta0) at  data/samples_ensemble/t_xz_train2.npy\n",
      "22:29    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25)\n",
      "22:29    Method:                 sally\n",
      "22:29    Hidden layers:          (100, 100)\n",
      "22:29    Activation function:    tanh\n",
      "22:29    Batch size:             128\n",
      "22:29    Trainer:                amsgrad\n",
      "22:29    Epochs:                 50\n",
      "22:29    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:29    Validation split:       None\n",
      "22:29    Early stopping:         True\n",
      "22:29    Scale inputs:           True\n",
      "22:29    Shuffle labels          False\n",
      "22:29    Regularization:         None\n",
      "22:29  Loading training data\n",
      "22:29  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:29  Rescaling inputs\n",
      "22:29  Only using 21 of 26 observables\n",
      "22:29  Creating model for method sally\n",
      "22:29  Training model\n",
      "22:29    Epoch 5: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:29    Epoch 10: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:29    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:30    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:30    Epoch 25: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:30    Epoch 30: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:30    Epoch 35: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:30    Epoch 40: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:30    Epoch 45: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:30    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:30  Finished training\n",
      "22:30  Training estimator 4 / 5 in ensemble\n",
      "22:30  Starting training\n",
      "22:30    Method:                 sally\n",
      "22:30    Training data: x at data/samples_ensemble/x_train3.npy\n",
      "22:30                   t_xz (theta0) at  data/samples_ensemble/t_xz_train3.npy\n",
      "22:30    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25)\n",
      "22:30    Method:                 sally\n",
      "22:30    Hidden layers:          (100, 100)\n",
      "22:30    Activation function:    tanh\n",
      "22:30    Batch size:             128\n",
      "22:30    Trainer:                amsgrad\n",
      "22:30    Epochs:                 50\n",
      "22:30    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:30    Validation split:       None\n",
      "22:30    Early stopping:         True\n",
      "22:30    Scale inputs:           True\n",
      "22:30    Shuffle labels          False\n",
      "22:30    Regularization:         None\n",
      "22:30  Loading training data\n",
      "22:30  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:30  Rescaling inputs\n",
      "22:30  Only using 21 of 26 observables\n",
      "22:30  Creating model for method sally\n",
      "22:30  Training model\n",
      "22:30    Epoch 5: train loss 0.0008 (mse_score: 0.0008)\n",
      "22:30    Epoch 10: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:30    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:30    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 30: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 35: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 40: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 45: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:31  Finished training\n",
      "22:31  Training estimator 5 / 5 in ensemble\n",
      "22:31  Starting training\n",
      "22:31    Method:                 sally\n",
      "22:31    Training data: x at data/samples_ensemble/x_train4.npy\n",
      "22:31                   t_xz (theta0) at  data/samples_ensemble/t_xz_train4.npy\n",
      "22:31    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25)\n",
      "22:31    Method:                 sally\n",
      "22:31    Hidden layers:          (100, 100)\n",
      "22:31    Activation function:    tanh\n",
      "22:31    Batch size:             128\n",
      "22:31    Trainer:                amsgrad\n",
      "22:31    Epochs:                 50\n",
      "22:31    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:31    Validation split:       None\n",
      "22:31    Early stopping:         True\n",
      "22:31    Scale inputs:           True\n",
      "22:31    Shuffle labels          False\n",
      "22:31    Regularization:         None\n",
      "22:31  Loading training data\n",
      "22:31  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:31  Rescaling inputs\n",
      "22:31  Only using 21 of 26 observables\n",
      "22:31  Creating model for method sally\n",
      "22:31  Training model\n",
      "22:31    Epoch 5: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:31    Epoch 10: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:31    Epoch 30: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:32    Epoch 35: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:32    Epoch 40: train loss 0.0005 (mse_score: 0.0005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:32    Epoch 45: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:32    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:32  Finished training\n",
      "22:32  Training 5 estimators in ensemble\n",
      "22:32  Training estimator 1 / 5 in ensemble\n",
      "22:32  Starting training\n",
      "22:32    Method:                 sally\n",
      "22:32    Training data: x at data/samples_ensemble/x_train0.npy\n",
      "22:32                   t_xz (theta0) at  data/samples_ensemble/t_xz_train0.npy\n",
      "22:32    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23)\n",
      "22:32    Method:                 sally\n",
      "22:32    Hidden layers:          (100, 100)\n",
      "22:32    Activation function:    tanh\n",
      "22:32    Batch size:             128\n",
      "22:32    Trainer:                amsgrad\n",
      "22:32    Epochs:                 50\n",
      "22:32    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:32    Validation split:       None\n",
      "22:32    Early stopping:         True\n",
      "22:32    Scale inputs:           True\n",
      "22:32    Shuffle labels          False\n",
      "22:32    Regularization:         None\n",
      "22:32  Loading training data\n",
      "22:32  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:32  Rescaling inputs\n",
      "22:32  Only using 19 of 26 observables\n",
      "22:32  Creating model for method sally\n",
      "22:32  Training model\n",
      "22:32    Epoch 5: train loss 0.0008 (mse_score: 0.0008)\n",
      "22:32    Epoch 10: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:32    Epoch 15: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:32    Epoch 20: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:32    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:32    Epoch 30: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:32    Epoch 35: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:32    Epoch 40: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:32    Epoch 45: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 50: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33  Finished training\n",
      "22:33  Training estimator 2 / 5 in ensemble\n",
      "22:33  Starting training\n",
      "22:33    Method:                 sally\n",
      "22:33    Training data: x at data/samples_ensemble/x_train1.npy\n",
      "22:33                   t_xz (theta0) at  data/samples_ensemble/t_xz_train1.npy\n",
      "22:33    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23)\n",
      "22:33    Method:                 sally\n",
      "22:33    Hidden layers:          (100, 100)\n",
      "22:33    Activation function:    tanh\n",
      "22:33    Batch size:             128\n",
      "22:33    Trainer:                amsgrad\n",
      "22:33    Epochs:                 50\n",
      "22:33    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:33    Validation split:       None\n",
      "22:33    Early stopping:         True\n",
      "22:33    Scale inputs:           True\n",
      "22:33    Shuffle labels          False\n",
      "22:33    Regularization:         None\n",
      "22:33  Loading training data\n",
      "22:33  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:33  Rescaling inputs\n",
      "22:33  Only using 19 of 26 observables\n",
      "22:33  Creating model for method sally\n",
      "22:33  Training model\n",
      "22:33    Epoch 5: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:33    Epoch 10: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:33    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 30: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 35: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 40: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 45: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33    Epoch 50: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:33  Finished training\n",
      "22:33  Training estimator 3 / 5 in ensemble\n",
      "22:33  Starting training\n",
      "22:33    Method:                 sally\n",
      "22:33    Training data: x at data/samples_ensemble/x_train2.npy\n",
      "22:33                   t_xz (theta0) at  data/samples_ensemble/t_xz_train2.npy\n",
      "22:33    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23)\n",
      "22:33    Method:                 sally\n",
      "22:33    Hidden layers:          (100, 100)\n",
      "22:33    Activation function:    tanh\n",
      "22:33    Batch size:             128\n",
      "22:33    Trainer:                amsgrad\n",
      "22:33    Epochs:                 50\n",
      "22:33    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:33    Validation split:       None\n",
      "22:33    Early stopping:         True\n",
      "22:33    Scale inputs:           True\n",
      "22:33    Shuffle labels          False\n",
      "22:33    Regularization:         None\n",
      "22:33  Loading training data\n",
      "22:33  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:33  Rescaling inputs\n",
      "22:33  Only using 19 of 26 observables\n",
      "22:33  Creating model for method sally\n",
      "22:33  Training model\n",
      "22:34    Epoch 5: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:34    Epoch 10: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:34    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:34    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:34    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:34    Epoch 30: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:34    Epoch 35: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:34    Epoch 40: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:34    Epoch 45: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:34    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:34  Finished training\n",
      "22:34  Training estimator 4 / 5 in ensemble\n",
      "22:34  Starting training\n",
      "22:34    Method:                 sally\n",
      "22:34    Training data: x at data/samples_ensemble/x_train3.npy\n",
      "22:34                   t_xz (theta0) at  data/samples_ensemble/t_xz_train3.npy\n",
      "22:34    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23)\n",
      "22:34    Method:                 sally\n",
      "22:34    Hidden layers:          (100, 100)\n",
      "22:34    Activation function:    tanh\n",
      "22:34    Batch size:             128\n",
      "22:34    Trainer:                amsgrad\n",
      "22:34    Epochs:                 50\n",
      "22:34    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:34    Validation split:       None\n",
      "22:34    Early stopping:         True\n",
      "22:34    Scale inputs:           True\n",
      "22:34    Shuffle labels          False\n",
      "22:34    Regularization:         None\n",
      "22:34  Loading training data\n",
      "22:34  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:34  Rescaling inputs\n",
      "22:34  Only using 19 of 26 observables\n",
      "22:34  Creating model for method sally\n",
      "22:34  Training model\n",
      "22:34    Epoch 5: train loss 0.0008 (mse_score: 0.0008)\n",
      "22:34    Epoch 10: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:35    Epoch 15: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:35    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 30: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 35: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 40: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 45: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 50: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35  Finished training\n",
      "22:35  Training estimator 5 / 5 in ensemble\n",
      "22:35  Starting training\n",
      "22:35    Method:                 sally\n",
      "22:35    Training data: x at data/samples_ensemble/x_train4.npy\n",
      "22:35                   t_xz (theta0) at  data/samples_ensemble/t_xz_train4.npy\n",
      "22:35    Features:               (0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23)\n",
      "22:35    Method:                 sally\n",
      "22:35    Hidden layers:          (100, 100)\n",
      "22:35    Activation function:    tanh\n",
      "22:35    Batch size:             128\n",
      "22:35    Trainer:                amsgrad\n",
      "22:35    Epochs:                 50\n",
      "22:35    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:35    Validation split:       None\n",
      "22:35    Early stopping:         True\n",
      "22:35    Scale inputs:           True\n",
      "22:35    Shuffle labels          False\n",
      "22:35    Regularization:         None\n",
      "22:35  Loading training data\n",
      "22:35  Found 50000 samples with 2 parameters and 26 observables\n",
      "22:35  Rescaling inputs\n",
      "22:35  Only using 19 of 26 observables\n",
      "22:35  Creating model for method sally\n",
      "22:35  Training model\n",
      "22:35    Epoch 5: train loss 0.0007 (mse_score: 0.0007)\n",
      "22:35    Epoch 10: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 15: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 20: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 25: train loss 0.0006 (mse_score: 0.0006)\n",
      "22:35    Epoch 30: train loss 0.0005 (mse_score: 0.0005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:36    Epoch 35: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:36    Epoch 40: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:36    Epoch 45: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:36    Epoch 50: train loss 0.0005 (mse_score: 0.0005)\n",
      "22:36  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_met = EnsembleForge(estimators=n_estimators)\n",
    "ensemble_met.train_all(\n",
    "    method='sally',\n",
    "    x_filename=['data/samples_ensemble/x_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=['data/samples_ensemble/t_xz_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    features=(0,1,2, 3,4,5, 6,8, 9,11, 12,13,14, 15,17, 18,19,20, 23, 24,25)\n",
    ")\n",
    "ensemble_met.save('models/samples_metonly')\n",
    "\n",
    "\n",
    "ensemble_xxx = EnsembleForge(estimators=n_estimators)\n",
    "ensemble_xxx.train_all(\n",
    "    method='sally',\n",
    "    x_filename=['data/samples_ensemble/x_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=['data/samples_ensemble/t_xz_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    features=(0,1,2, 3,4,5, 6,8, 9,11, 12,13,14, 15,17, 18,19,20, 23)\n",
    ")\n",
    "ensemble_xxx.save('models/samples_xxxonly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6d) Evaluate Fisher Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any evaluation of this ensemble will provide us with mean and variance of the predictions. Let's try that for the Fisher information: **Fix Lumi Bug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:36  Loading data from data/madminer_lhedata.h5\n",
      "22:36  Found 2 parameters:\n",
      "22:36     CWL2 (LHA: dim6 2, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:36     CPWL2 (LHA: dim6 5, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:36  Found 6 benchmarks:\n",
      "22:36     sm: CWL2 = 0.00e+00, CPWL2 = 0.00e+00\n",
      "22:36     w: CWL2 = 20.00, CPWL2 = 0.00e+00\n",
      "22:36     morphing_basis_vector_2: CWL2 = -3.26e+01, CPWL2 = -4.46e+01\n",
      "22:36     morphing_basis_vector_3: CWL2 = 8.14, CPWL2 = -3.50e+01\n",
      "22:36     morphing_basis_vector_4: CWL2 = -3.51e+01, CPWL2 = 32.41\n",
      "22:36     morphing_basis_vector_5: CWL2 = 5.86, CPWL2 = 39.09\n",
      "22:36  Found 26 observables: px_l, px_v, px_a, py_l, py_v, py_a, pz_l, pz_v, pz_a, e_l, e_v, e_a, pt_l, pt_v, pt_a, eta_l, eta_v, eta_a, dphi_lv, dphi_la, dphi_va, m_lv, m_lva, m_la, mtrans, phi_resurrection\n",
      "22:36  Found 100000 events\n",
      "22:36  Found morphing setup with 6 components\n",
      "22:36  Evaluating rate Fisher information\n",
      "22:36  Found ensemble with 5 estimators and expectations None\n",
      "22:36  Evaluating rate Fisher information\n",
      "22:36  Found ensemble with 5 estimators and expectations None\n",
      "22:36  Evaluating rate Fisher information\n",
      "22:36  Found ensemble with 5 estimators and expectations None\n"
     ]
    }
   ],
   "source": [
    "fisher = FisherInformation(lhedatafile, debug=False)\n",
    "\n",
    "fi_ml_mean, fi_ml_covariance = fisher.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    model_file='models/samples_ensemble',\n",
    "    unweighted_x_sample_file='data/samples_ensemble/x_test.npy',\n",
    "    luminosity=300*1000./nsamples\n",
    ")\n",
    "\n",
    "fi_metonly_mean, fi_metonly_covariance = fisher.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    model_file='models/samples_metonly',\n",
    "    unweighted_x_sample_file='data/samples_ensemble/x_test.npy',\n",
    "    luminosity=300*1000./nsamples\n",
    ")\n",
    "\n",
    "fi_xxxonly_mean, fi_xxxonly_covariance = fisher.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    model_file='models/samples_xxxonly',\n",
    "    unweighted_x_sample_file='data/samples_ensemble/x_test.npy',\n",
    "    luminosity=300*1000./nsamples\n",
    ")\n",
    "\n",
    "fi_truth_mean, fi_truth_covariance = fisher.calculate_fisher_information_full_truth(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300*1000./nsamples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance can be propagated to the Fisher distance contour plot easily. Note that this also includes uncertainty bands corresponding to the uncertainty of the Machine Learning. This uncertainty corresponds to the standard devisation of the different ensemble constituents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f80ff90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plot_fisher_information_contours_2d(\n",
    "    [fi_ml_mean, fi_metonly_mean,fi_xxxonly_mean, fi_truth_mean ],\n",
    "    [fi_ml_covariance, fi_metonly_covariance,fi_xxxonly_covariance, fi_truth_covariance],\n",
    "    colors=[u'C0',u'C1',u'C2',\"black\"],\n",
    "    linestyles=[\"solid\",\"solid\",\"solid\",\"dashed\"],\n",
    "    inline_labels=[\"ML-all\",\"ML-MET\",\"ML-Phi\",\"truth\"],\n",
    "    xrange=(-10,10),\n",
    "    yrange=(-5,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
